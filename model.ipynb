{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcd8c316",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\viet ha\\anaconda3\\lib\\site-packages\\statsmodels\\compat\\pandas.py:61: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import Int64Index as NumericIndex\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.api.types import CategoricalDtype\n",
    "import sklearn.model_selection\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.formula.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "831bda03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('facemask.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e78e1d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_res_9(data):\n",
    "    dictz = {\n",
    "        'Slightly Agree': 3,\n",
    "        'Definitely Agree': 2,\n",
    "        'Definitely Disagree': 1,\n",
    "        'Slightly Disagree': 0\n",
    "    }\n",
    "    for c in data.columns[-25:-15]:\n",
    "        data[c] = data[c].replace(dictz)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a79f8cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_res_6(data):\n",
    "    dictz = {\n",
    "        'Disagree strongly': -2,\n",
    "        'Disagree a little': -1,\n",
    "        'Neutral; no opinion': 0,\n",
    "        'Agree a little': 1,\n",
    "        'Agree strongly': 2\n",
    "    }\n",
    "    for c in data.columns[-15:]:\n",
    "        data[c] = data[c].replace(dictz)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a9d3dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all responses' columns, add 2 summary variables\n",
    "def add_summary_responses(data):\n",
    "    data['res_6'] = data[data.columns[-15:]].sum(axis=1)\n",
    "    data['res_9'] = data[data.columns[-25:-10]].sum(axis=1)\n",
    "    data.drop(columns=list(data.columns[-27:-2]), inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ebc851a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix the 'country' column\n",
    "def fix_country(data):\n",
    "    data.loc[data['country_text'] == 'Bulgaria', 'country'] = 'Bulgaria'\n",
    "    data.loc[data['country_text'] == 'Poland', 'country'] = 'Poland'\n",
    "    data.loc[data['country_text'] == 'Greece', 'country'] = 'Greece'\n",
    "    data.loc[data['country_text'] == 'Ukraine', 'country'] = 'Ukraine'\n",
    "    data.loc[data['country_text'] == 'ukraine', 'country'] = 'Ukraine'\n",
    "    data.loc[data['country_text'] == 'Mexico', 'country'] = 'Mexico'\n",
    "    data.loc[data['country_text'] == 'Portugal', 'country'] = 'Portugal'\n",
    "    data.loc[data['country_text'] == 'sweden', 'country'] = 'Sweden'\n",
    "    data.loc[data['country_text'] == '1', 'country'] = 'NaN'\n",
    "    data.loc[data['country_text'] == 'The Netherlands', 'country'] = 'Netherlands'\n",
    "    data.loc[data['country_text'] == 'the Netherlands', 'country'] = 'Netherlands'\n",
    "    data.loc[data['country_text'] == 'Netherlands', 'country'] = 'Netherlands'\n",
    "    data.loc[data['country_text'] == 'Belarus', 'country'] = 'Belarus'\n",
    "    data.loc[data['country_text'] == 'The Russian Federation', 'country'] = 'Russia'\n",
    "    data.loc[data['country_text'] == 'Russia', 'country'] = 'Russia'\n",
    "    data.loc[data['country_text'] == 'first 3 years of my life: Australia; then: Germany', 'country'] = 'Australia, Germany'\n",
    "    data.loc[data['country_text'] == 'Spain', 'country'] = 'Spain'\n",
    "    data.loc[data['country_text'] == 'spain', 'country'] = 'Spain'\n",
    "    data.loc[data['country_text'] == 'Armenia', 'country'] = 'Armenia'\n",
    "    data.loc[data['country_text'] == 'China', 'country'] = 'China'\n",
    "    data.loc[data['country_text'] == 'PRC', 'country'] = 'China'\n",
    "    data.loc[data['country_text'] == 'Thailand (until the age of 11), England (from 12-21)', 'country'] = 'England, Thailand'\n",
    "    data.loc[data['country_text'] == 'Estonia', 'country'] = 'Estonia'\n",
    "    data.loc[data['country_text'] == 'HONG KONG', 'country'] = 'Hong Kong'\n",
    "    data.loc[data['country_text'] == 'Hong Kong', 'country'] = 'Hong Kong'\n",
    "    data.loc[data['country_text'] == 'HK', 'country'] = 'Hong Kong'\n",
    "    data.loc[data['country_text'] == 'Italy', 'country'] = 'Italy'\n",
    "    data.loc[data['country_text'] == 'Brazil', 'country'] = 'Brazil'\n",
    "    data.loc[data['country_text'] == 'COLOMBIA', 'country'] = 'Colombia'\n",
    "    data.loc[data['country_text'] == 'colombia', 'country'] = 'Colombia'\n",
    "    data.loc[data['country_text'] == 'France', 'country'] = 'France'\n",
    "    data.loc[data['country_text'] == 'Finland', 'country'] = 'Finland'\n",
    "    data.loc[data['country_text'] == 'Belgium', 'country'] = 'Belgium'\n",
    "    data.loc[data['country_text'] == 'Korea/US', 'country'] = 'Korea, United States'\n",
    "    data.loc[data['country_text'] == 'Turkey', 'country'] = 'Turkey'\n",
    "    data.loc[data['country_text'] == 'Kasachstan', 'country'] = 'Kazakhstan'\n",
    "    data.loc[data['country_text'] == 'Romania', 'country'] = 'Romania'\n",
    "    data.loc[data['country_text'] == 'Lithuania', 'country'] = 'Lithuania'\n",
    "    data.loc[data['country_text'] == 'Taiwan', 'country'] = 'Taiwan'\n",
    "    data.loc[data['country_text'] == 'Saudi Arabia', 'country'] = 'Saudi Arabia'\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "912270c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_country(data, en_speak_country):\n",
    "    for i in range(len(data)):\n",
    "        for c in en_speak_country:\n",
    "            if c in data['country'][i]:\n",
    "                data.at[i, 'country'] = 'Yes'\n",
    "    data.loc[data['country'] != 'Yes', 'country'] = 'No'\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "706319ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_missings_unnecessaries(data):\n",
    "    # now, we can drop 'country_text' without losing information \n",
    "    data.drop(['country_text'], axis=1, inplace=True)\n",
    "    # data guide: fricative is just like target. You can ignore it. \n",
    "    # You can also ignore minimal_pair for the scope of this work.\n",
    "    data.drop(['fricative', 'minimal_pair'], axis=1, inplace=True)\n",
    "    # data guide: spreadsheet_name, spreadsheet_row and trial_number are \n",
    "    # most likely things you will not be touching during your analysis\n",
    "    data.drop(['spreadsheet_name', 'spreadsheet_row', 'trial_number'], axis=1, inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fed940c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_vaccine(data, predictor):\n",
    "    cats = ['not sure', 'no', 'yes']\n",
    "    cat_type = CategoricalDtype(categories=cats)\n",
    "    data[predictor] = data[predictor].astype(cat_type)\n",
    "    data = pd.get_dummies(data, prefix= predictor, columns=[predictor], drop_first=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b561dffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_gender(data, predictor):\n",
    "    cats = ['prefer not to say', 'non-binary', 'no', 'yes']\n",
    "    cat_type = CategoricalDtype(categories=cats)\n",
    "    data[predictor] = data[predictor].astype(cat_type)\n",
    "    data = pd.get_dummies(data, prefix= predictor, columns=[predictor], drop_first=False)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "192fa2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_political(data, predictor):\n",
    "    cats = ['prefer not to say', 'left/liberal', 'center', 'right/concervative']\n",
    "    cat_type = CategoricalDtype(categories=cats)\n",
    "    data[predictor] = data[predictor].astype(cat_type)\n",
    "    data = pd.get_dummies(data, prefix= predictor, columns=[predictor], drop_first=False)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "672bc0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_education(data, predictor):\n",
    "    cats = ['Other (please specify)', 'high school', 'some college', 'BA/BSc', 'MA/MSc', 'PhD']\n",
    "    cat_type = CategoricalDtype(categories=cats)\n",
    "    data[predictor] = data[predictor].astype(cat_type)\n",
    "    data = pd.get_dummies(data, prefix= predictor, columns=[predictor], drop_first=False)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1345582",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_target(data, predictor):\n",
    "    cats = ['S', 'SH', 'F', 'TH', 'X']\n",
    "    cat_type = CategoricalDtype(categories=cats)\n",
    "    data[predictor] = data[predictor].astype(cat_type)\n",
    "    data = pd.get_dummies(data, prefix= predictor, columns=[predictor], drop_first=False)\n",
    "    # drop answer, because 'target' and 'correct' together make answer redundant\n",
    "    data.drop(['answer'], axis=1, inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf6f951f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_binary(data, predictor):\n",
    "    cats = ['No', 'Yes']\n",
    "    cat_type = CategoricalDtype(categories=cats)\n",
    "    data[predictor] = data[predictor].astype(cat_type)\n",
    "    data = pd.get_dummies(data, prefix= predictor, columns=[predictor], drop_first=False)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37f29d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_condition(data, predictor):\n",
    "    cats = ['NW', 'WM']\n",
    "    cat_type = CategoricalDtype(categories=cats)\n",
    "    data[predictor] = data[predictor].astype(cat_type)\n",
    "    data = pd.get_dummies(data, prefix= predictor, columns=[predictor], drop_first=False)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71cae13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_logfreq(data):\n",
    "    lf = data['logfreq'].unique()\n",
    "    data['logfreq'] = data['logfreq'].replace(dict(zip(sorted(lf), np.arange(len(lf)))))\n",
    "    # drop item, because item is now represented by its rank\n",
    "    data.drop(['item'], axis=1, inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0459812d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_syllable(data, predictor):\n",
    "    cats = ['onset', 'coda']\n",
    "    cat_type = CategoricalDtype(categories=cats)\n",
    "    data[predictor] = data[predictor].astype(cat_type)\n",
    "    data = pd.get_dummies(data, prefix= predictor, columns=[predictor], drop_first=False)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9920cee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_device(data, predictor):\n",
    "    cats = ['mobile', 'computer', 'tablet']\n",
    "    cat_type = CategoricalDtype(categories=cats)\n",
    "    data[predictor] = data[predictor].astype(cat_type)\n",
    "    data = pd.get_dummies(data, prefix= predictor, columns=[predictor], drop_first=False)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74ec11a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_browser(data, predictor):\n",
    "    for i in range(len(data)):\n",
    "        for br in ['Safari', 'Firefox', 'Chrome', 'Edge', 'Opera']:\n",
    "            if br in data['participant_browser'][i]:\n",
    "                data.at[i, 'participant_browser'] = br\n",
    "    cats = ['Safari', 'Firefox', 'Chrome', 'Edge', 'Opera']\n",
    "    cat_type = CategoricalDtype(categories=cats)\n",
    "    data[predictor] = data[predictor].astype(cat_type)\n",
    "    data = pd.get_dummies(data, prefix= predictor, columns=[predictor], drop_first=False)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90401171",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_boolean(data, predictor):\n",
    "    cats = [True, False]\n",
    "    cat_type = CategoricalDtype(categories=cats)\n",
    "    data[predictor] = data[predictor].astype(cat_type)\n",
    "    data = pd.get_dummies(data, prefix= predictor, columns=[predictor], drop_first=False)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "27c00290",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(data, c):\n",
    "    data[c] = (data[c] - data[c].mean())/data[c].std()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "93f8734e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(data):\n",
    "    data = (\n",
    "        data\n",
    "        .pipe(fix_country)\n",
    "        .pipe(transform_res_9)\n",
    "        .pipe(transform_res_6)\n",
    "        .pipe(add_summary_responses)\n",
    "        .pipe(drop_missings_unnecessaries)\n",
    "        .pipe(transform_vaccine, 'vaccine')\n",
    "        .pipe(transform_gender, 'gender')\n",
    "        .pipe(transform_political, 'political')\n",
    "        .pipe(transform_education, 'education')\n",
    "        .pipe(transform_binary, 'glasses')\n",
    "        .pipe(transform_binary, 'impairment')\n",
    "        .pipe(transform_condition, 'condition')\n",
    "        .pipe(transform_logfreq)\n",
    "        .pipe(transform_target, 'target')\n",
    "        .pipe(transform_syllable, 'syllable')\n",
    "        .pipe(transform_device, 'participant_device_type')\n",
    "        .pipe(transform_browser, 'participant_browser')\n",
    "        .pipe(transform_country, ['England', 'United States', 'Australia'])\n",
    "        .pipe(transform_binary, 'country')\n",
    "        #.pipe(transform_boolean, 'correct')\n",
    "        .pipe(transform_boolean, 'visual_cues')\n",
    "        .pipe(standardize, 'mask_before')\n",
    "        .pipe(standardize, 'mask_people')\n",
    "        .pipe(standardize, 'mask_perception')\n",
    "        .pipe(standardize, 'mask_spread')\n",
    "        .pipe(standardize, 'mask_freedom')\n",
    "        .pipe(standardize, 'mask_vulnerable')\n",
    "        .pipe(standardize, 'intensity')\n",
    "        .pipe(standardize, 'cog')\n",
    "        .pipe(standardize, 'f1')\n",
    "        .pipe(standardize, 'f2')\n",
    "        .pipe(standardize, 'logfreq')\n",
    "        .pipe(standardize, 'rt')\n",
    "    ) \n",
    "    \n",
    "    # for now, just remove country, vowel, and don't care about who took the experiment\n",
    "    X = data.drop(['correct', 'vowel', 'participant_private_id'], axis = 1)\n",
    "    y = data['correct']\n",
    "    y = [x+0 for x in y]\n",
    "    data = data.drop(['vowel', 'participant_private_id'], axis = 1)\n",
    "    data['correct'] = y\n",
    "    return X, y, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7387546d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rt</th>\n",
       "      <th>correct</th>\n",
       "      <th>logfreq</th>\n",
       "      <th>intensity</th>\n",
       "      <th>cog</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>loudness_accuracy</th>\n",
       "      <th>mgcurk_rate</th>\n",
       "      <th>age</th>\n",
       "      <th>...</th>\n",
       "      <th>participant_device_type_tablet</th>\n",
       "      <th>participant_browser_Safari</th>\n",
       "      <th>participant_browser_Firefox</th>\n",
       "      <th>participant_browser_Chrome</th>\n",
       "      <th>participant_browser_Edge</th>\n",
       "      <th>participant_browser_Opera</th>\n",
       "      <th>country_No</th>\n",
       "      <th>country_Yes</th>\n",
       "      <th>visual_cues_True</th>\n",
       "      <th>visual_cues_False</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.114404</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.357448</td>\n",
       "      <td>1.827673</td>\n",
       "      <td>0.598759</td>\n",
       "      <td>0.389142</td>\n",
       "      <td>-0.000216</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.114404</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.357448</td>\n",
       "      <td>0.752391</td>\n",
       "      <td>0.945420</td>\n",
       "      <td>0.772389</td>\n",
       "      <td>0.294794</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.072996</td>\n",
       "      <td>1</td>\n",
       "      <td>1.281805</td>\n",
       "      <td>0.731831</td>\n",
       "      <td>0.309690</td>\n",
       "      <td>1.742549</td>\n",
       "      <td>0.625340</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.072996</td>\n",
       "      <td>1</td>\n",
       "      <td>1.281805</td>\n",
       "      <td>-0.117329</td>\n",
       "      <td>0.342363</td>\n",
       "      <td>0.986356</td>\n",
       "      <td>0.686283</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.128597</td>\n",
       "      <td>0</td>\n",
       "      <td>0.917526</td>\n",
       "      <td>-0.536751</td>\n",
       "      <td>-1.076401</td>\n",
       "      <td>-0.576647</td>\n",
       "      <td>1.372278</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27195</th>\n",
       "      <td>-0.109228</td>\n",
       "      <td>1</td>\n",
       "      <td>1.555014</td>\n",
       "      <td>-1.371132</td>\n",
       "      <td>-1.327813</td>\n",
       "      <td>1.538468</td>\n",
       "      <td>0.702497</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27196</th>\n",
       "      <td>0.019672</td>\n",
       "      <td>1</td>\n",
       "      <td>0.644318</td>\n",
       "      <td>1.432830</td>\n",
       "      <td>-0.706481</td>\n",
       "      <td>1.805643</td>\n",
       "      <td>0.691699</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27197</th>\n",
       "      <td>0.019672</td>\n",
       "      <td>1</td>\n",
       "      <td>0.644318</td>\n",
       "      <td>0.463077</td>\n",
       "      <td>-1.672813</td>\n",
       "      <td>0.678121</td>\n",
       "      <td>0.317890</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27198</th>\n",
       "      <td>-0.097373</td>\n",
       "      <td>1</td>\n",
       "      <td>0.735387</td>\n",
       "      <td>-0.667149</td>\n",
       "      <td>-0.944049</td>\n",
       "      <td>-1.349019</td>\n",
       "      <td>-0.257677</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27199</th>\n",
       "      <td>-0.097373</td>\n",
       "      <td>1</td>\n",
       "      <td>0.735387</td>\n",
       "      <td>-1.660456</td>\n",
       "      <td>-0.493279</td>\n",
       "      <td>-1.265678</td>\n",
       "      <td>-0.359210</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27200 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             rt  correct   logfreq  intensity       cog        f1        f2  \\\n",
       "0     -0.114404        1 -0.357448   1.827673  0.598759  0.389142 -0.000216   \n",
       "1     -0.114404        1 -0.357448   0.752391  0.945420  0.772389  0.294794   \n",
       "2     -0.072996        1  1.281805   0.731831  0.309690  1.742549  0.625340   \n",
       "3     -0.072996        1  1.281805  -0.117329  0.342363  0.986356  0.686283   \n",
       "4     -0.128597        0  0.917526  -0.536751 -1.076401 -0.576647  1.372278   \n",
       "...         ...      ...       ...        ...       ...       ...       ...   \n",
       "27195 -0.109228        1  1.555014  -1.371132 -1.327813  1.538468  0.702497   \n",
       "27196  0.019672        1  0.644318   1.432830 -0.706481  1.805643  0.691699   \n",
       "27197  0.019672        1  0.644318   0.463077 -1.672813  0.678121  0.317890   \n",
       "27198 -0.097373        1  0.735387  -0.667149 -0.944049 -1.349019 -0.257677   \n",
       "27199 -0.097373        1  0.735387  -1.660456 -0.493279 -1.265678 -0.359210   \n",
       "\n",
       "       loudness_accuracy  mgcurk_rate  age  ...  \\\n",
       "0                    0.8          0.5   19  ...   \n",
       "1                    0.8          0.5   19  ...   \n",
       "2                    0.8          0.5   19  ...   \n",
       "3                    0.8          0.5   19  ...   \n",
       "4                    0.8          0.5   19  ...   \n",
       "...                  ...          ...  ...  ...   \n",
       "27195                1.0          1.0   34  ...   \n",
       "27196                1.0          1.0   34  ...   \n",
       "27197                1.0          1.0   34  ...   \n",
       "27198                1.0          1.0   34  ...   \n",
       "27199                1.0          1.0   34  ...   \n",
       "\n",
       "       participant_device_type_tablet  participant_browser_Safari  \\\n",
       "0                                   0                           1   \n",
       "1                                   0                           1   \n",
       "2                                   0                           1   \n",
       "3                                   0                           1   \n",
       "4                                   0                           1   \n",
       "...                               ...                         ...   \n",
       "27195                               0                           0   \n",
       "27196                               0                           0   \n",
       "27197                               0                           0   \n",
       "27198                               0                           0   \n",
       "27199                               0                           0   \n",
       "\n",
       "       participant_browser_Firefox  participant_browser_Chrome  \\\n",
       "0                                0                           0   \n",
       "1                                0                           0   \n",
       "2                                0                           0   \n",
       "3                                0                           0   \n",
       "4                                0                           0   \n",
       "...                            ...                         ...   \n",
       "27195                            0                           1   \n",
       "27196                            0                           1   \n",
       "27197                            0                           1   \n",
       "27198                            0                           1   \n",
       "27199                            0                           1   \n",
       "\n",
       "       participant_browser_Edge  participant_browser_Opera  country_No  \\\n",
       "0                             0                          0           1   \n",
       "1                             0                          0           1   \n",
       "2                             0                          0           1   \n",
       "3                             0                          0           1   \n",
       "4                             0                          0           1   \n",
       "...                         ...                        ...         ...   \n",
       "27195                         0                          0           0   \n",
       "27196                         0                          0           0   \n",
       "27197                         0                          0           0   \n",
       "27198                         0                          0           0   \n",
       "27199                         0                          0           0   \n",
       "\n",
       "       country_Yes  visual_cues_True  visual_cues_False  \n",
       "0                0                 0                  1  \n",
       "1                0                 0                  1  \n",
       "2                0                 0                  1  \n",
       "3                0                 0                  1  \n",
       "4                0                 0                  1  \n",
       "...            ...               ...                ...  \n",
       "27195            1                 1                  0  \n",
       "27196            1                 0                  1  \n",
       "27197            1                 0                  1  \n",
       "27198            1                 1                  0  \n",
       "27199            1                 1                  0  \n",
       "\n",
       "[27200 rows x 60 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('facemask.csv')\n",
    "#df.pipe(fix_country)\n",
    "X, y, data = process_data(df)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "83e40b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df, n_samples=df.shape[0], validation=False):\n",
    "    if validation:\n",
    "        sample = df.sample(n=n_samples)\n",
    "\n",
    "        msk = np.random.rand(len(sample)) < 0.8\n",
    "        non_test = sample[msk]\n",
    "        test = sample[~msk]\n",
    "        \n",
    "        msk = np.random.rand(len(non_test)) < 0.7\n",
    "        train = non_test[msk]\n",
    "        validation = non_test[~msk]\n",
    "        \n",
    "        return train, validation, test\n",
    "    \n",
    "    else:\n",
    "        sample = df.sample(n=n_samples)\n",
    "\n",
    "        msk = np.random.rand(len(sample)) < 0.8\n",
    "        train = sample[msk]\n",
    "        test = sample[~msk]\n",
    "        \n",
    "        return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "69a8fc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validation, test = train_test_split(data, validation=True)\n",
    "\n",
    "y_train = train['correct'].values\n",
    "y_val = validation['correct'].values\n",
    "y_test = test['correct'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "5955e3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = [y+0 for y in y_train]\n",
    "y_test = [y+0 for y in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f0cab20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictors = list(X.columns)\n",
    "\n",
    "predictors = [([], 0)]\n",
    "\n",
    "regression_model = LinearRegression(fit_intercept=True)\n",
    "\n",
    "R_sq_fwd = []\n",
    "\n",
    "for k in range(1, len(all_predictors)):\n",
    "    best_k_minus_1 = predictors[-1][0]\n",
    "\n",
    "    new_predictors = list(set(all_predictors) - set(best_k_minus_1))\n",
    "    validation_R_sqs = []\n",
    "\n",
    "    for predictor in new_predictors:\n",
    "\n",
    "        k_predictors = best_k_minus_1 + [predictor]\n",
    "        \n",
    "        X_train = train[k_predictors].values\n",
    "        X_val = validation[k_predictors].values\n",
    "        \n",
    "        if k == 1:\n",
    "            X_train = X_train.reshape((len(X_train), 1))\n",
    "            \n",
    "        regression_model.fit(X_train, y_train)\n",
    "        validation_R_sqs.append(regression_model.score(X_val, y_val))\n",
    "    \n",
    "    best_k = best_k_minus_1 + [new_predictors[np.argmax(validation_R_sqs)]]\n",
    "    R_sq_fwd.append(np.max(validation_R_sqs))\n",
    "    predictors.append((best_k, np.max(validation_R_sqs)))\n",
    "\n",
    "X_train = train[all_predictors].values\n",
    "X_val = validation[all_predictors].values  \n",
    "regression_model.fit(X_train, y_train)\n",
    "\n",
    "predictors.append((all_predictors, regression_model.score(X_val, y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "6950870d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best predictor set: ['target_X', 'target_TH', 'target_F', 'condition_WM', 'logfreq', 'f2', 'intensity', 'syllable_coda', 'f1', 'cog', 'mask_spread', 'country_Yes', 'impairment_Yes', 'syllable_onset', 'vaccine_yes', 'participant_browser_Edge', 'gender_non-binary', 'rt', 'education_some college', 'glasses_Yes', 'participant_browser_Safari', 'participant_browser_Opera', 'education_high school', 'visual_cues_False', 'political_center']\n",
      "validation R^2: 0.3061080620097769\n",
      "test R^2: 0.3239833013454233\n"
     ]
    }
   ],
   "source": [
    "best_predictor_set = sorted(predictors, key=lambda t: t[1])[-1]\n",
    "\n",
    "X_train = train[best_predictor_set[0]].values\n",
    "X_val = validation[best_predictor_set[0]].values  \n",
    "X_test = test[best_predictor_set[0]].values  \n",
    "\n",
    "regression_model.fit(np.vstack((X_train, X_val)), np.hstack((y_train, y_val)))\n",
    "\n",
    "print('best predictor set: {}\\nvalidation R^2: {}\\ntest R^2: {}'.format(best_predictor_set[0], best_predictor_set[1], regression_model.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "9c44c1b6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>correct</td>     <th>  R-squared:         </th> <td>   0.304</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.303</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   658.7</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 20 Mar 2022</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>01:32:53</td>     <th>  Log-Likelihood:    </th> <td> -7233.3</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 27200</td>      <th>  AIC:               </th> <td>1.450e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 27181</td>      <th>  BIC:               </th> <td>1.466e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    18</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "               <td></td>                 <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                  <td>-6.337e+11</td> <td> 3.94e+11</td> <td>   -1.608</td> <td> 0.108</td> <td>-1.41e+12</td> <td> 1.39e+11</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>target_X</th>                   <td>   -0.9954</td> <td>    0.013</td> <td>  -76.378</td> <td> 0.000</td> <td>   -1.021</td> <td>   -0.970</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>target_TH</th>                  <td>   -0.3615</td> <td>    0.008</td> <td>  -44.322</td> <td> 0.000</td> <td>   -0.377</td> <td>   -0.346</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>target_F</th>                   <td>   -0.1906</td> <td>    0.009</td> <td>  -21.690</td> <td> 0.000</td> <td>   -0.208</td> <td>   -0.173</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>condition_WM</th>               <td>   -0.0603</td> <td>    0.004</td> <td>  -13.562</td> <td> 0.000</td> <td>   -0.069</td> <td>   -0.052</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>logfreq</th>                    <td>    0.0309</td> <td>    0.002</td> <td>   15.626</td> <td> 0.000</td> <td>    0.027</td> <td>    0.035</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intensity</th>                  <td>   -0.0530</td> <td>    0.004</td> <td>  -12.569</td> <td> 0.000</td> <td>   -0.061</td> <td>   -0.045</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>syllable_coda</th>              <td> 6.337e+11</td> <td> 3.94e+11</td> <td>    1.608</td> <td> 0.108</td> <td>-1.39e+11</td> <td> 1.41e+12</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>f1</th>                         <td>   -0.0228</td> <td>    0.002</td> <td>  -10.965</td> <td> 0.000</td> <td>   -0.027</td> <td>   -0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>f2</th>                         <td>   -0.0225</td> <td>    0.002</td> <td>  -10.808</td> <td> 0.000</td> <td>   -0.027</td> <td>   -0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cog</th>                        <td>   -0.0163</td> <td>    0.002</td> <td>   -7.294</td> <td> 0.000</td> <td>   -0.021</td> <td>   -0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>country_Yes</th>                <td>    0.0359</td> <td>    0.005</td> <td>    7.080</td> <td> 0.000</td> <td>    0.026</td> <td>    0.046</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>impairment_Yes</th>             <td>   -0.0554</td> <td>    0.011</td> <td>   -4.821</td> <td> 0.000</td> <td>   -0.078</td> <td>   -0.033</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>vaccine_yes</th>                <td>    0.0374</td> <td>    0.006</td> <td>    5.851</td> <td> 0.000</td> <td>    0.025</td> <td>    0.050</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mask_spread</th>                <td>   -0.0139</td> <td>    0.002</td> <td>   -7.015</td> <td> 0.000</td> <td>   -0.018</td> <td>   -0.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>syllable_onset</th>             <td> 6.337e+11</td> <td> 3.94e+11</td> <td>    1.608</td> <td> 0.108</td> <td>-1.39e+11</td> <td> 1.41e+12</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rt</th>                         <td>   -0.0044</td> <td>    0.002</td> <td>   -2.295</td> <td> 0.022</td> <td>   -0.008</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>participant_browser_Safari</th> <td>   -0.0216</td> <td>    0.011</td> <td>   -2.049</td> <td> 0.040</td> <td>   -0.042</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>participant_browser_Edge</th>   <td>   -0.0120</td> <td>    0.009</td> <td>   -1.378</td> <td> 0.168</td> <td>   -0.029</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>participant_browser_Opera</th>  <td>    0.0199</td> <td>    0.015</td> <td>    1.359</td> <td> 0.174</td> <td>   -0.009</td> <td>    0.049</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>7184.586</td> <th>  Durbin-Watson:     </th> <td>   1.010</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>15004.042</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td>-1.587</td>  <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 4.780</td>  <th>  Cond. No.          </th> <td>5.94e+14</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 2.14e-25. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                correct   R-squared:                       0.304\n",
       "Model:                            OLS   Adj. R-squared:                  0.303\n",
       "Method:                 Least Squares   F-statistic:                     658.7\n",
       "Date:                Sun, 20 Mar 2022   Prob (F-statistic):               0.00\n",
       "Time:                        01:32:53   Log-Likelihood:                -7233.3\n",
       "No. Observations:               27200   AIC:                         1.450e+04\n",
       "Df Residuals:                   27181   BIC:                         1.466e+04\n",
       "Df Model:                          18                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================================\n",
       "                                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------------\n",
       "Intercept                  -6.337e+11   3.94e+11     -1.608      0.108   -1.41e+12    1.39e+11\n",
       "target_X                      -0.9954      0.013    -76.378      0.000      -1.021      -0.970\n",
       "target_TH                     -0.3615      0.008    -44.322      0.000      -0.377      -0.346\n",
       "target_F                      -0.1906      0.009    -21.690      0.000      -0.208      -0.173\n",
       "condition_WM                  -0.0603      0.004    -13.562      0.000      -0.069      -0.052\n",
       "logfreq                        0.0309      0.002     15.626      0.000       0.027       0.035\n",
       "intensity                     -0.0530      0.004    -12.569      0.000      -0.061      -0.045\n",
       "syllable_coda               6.337e+11   3.94e+11      1.608      0.108   -1.39e+11    1.41e+12\n",
       "f1                            -0.0228      0.002    -10.965      0.000      -0.027      -0.019\n",
       "f2                            -0.0225      0.002    -10.808      0.000      -0.027      -0.018\n",
       "cog                           -0.0163      0.002     -7.294      0.000      -0.021      -0.012\n",
       "country_Yes                    0.0359      0.005      7.080      0.000       0.026       0.046\n",
       "impairment_Yes                -0.0554      0.011     -4.821      0.000      -0.078      -0.033\n",
       "vaccine_yes                    0.0374      0.006      5.851      0.000       0.025       0.050\n",
       "mask_spread                   -0.0139      0.002     -7.015      0.000      -0.018      -0.010\n",
       "syllable_onset              6.337e+11   3.94e+11      1.608      0.108   -1.39e+11    1.41e+12\n",
       "rt                            -0.0044      0.002     -2.295      0.022      -0.008      -0.001\n",
       "participant_browser_Safari    -0.0216      0.011     -2.049      0.040      -0.042      -0.001\n",
       "participant_browser_Edge      -0.0120      0.009     -1.378      0.168      -0.029       0.005\n",
       "participant_browser_Opera      0.0199      0.015      1.359      0.174      -0.009       0.049\n",
       "==============================================================================\n",
       "Omnibus:                     7184.586   Durbin-Watson:                   1.010\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            15004.042\n",
       "Skew:                          -1.587   Prob(JB):                         0.00\n",
       "Kurtosis:                       4.780   Cond. No.                     5.94e+14\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 2.14e-25. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt_md = sm.ols(formula='correct ~ target_X + target_TH + target_F + condition_WM + logfreq + intensity + syllable_coda + f1 + f2 + cog + country_Yes + impairment_Yes + vaccine_yes + mask_spread + syllable_onset + rt + participant_browser_Safari + participant_browser_Edge + participant_browser_Opera + rt', data=data).fit()\n",
    "rt_md.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8bade5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
